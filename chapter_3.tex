%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   Filename    : chapter_3.tex 
%
%   Description : This file will contain your Theoretical Framework.
%                 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Theoretical Framework}
\label{sec:theoframework}

This chapter presents the theoretical foundations that inform the development of a multimodal personality recognition framework for Filipino Instagram users. The discussion is organized around key technical pillars, including text and image processing, feature fusion techniques, machine learning theory, and the underlying personality psychology model.

\section{Text Processing Theory}

Textual data from Instagram captions provides valuable linguistic cues for personality inference. This study employs the \textit{Vector Space Model} (Salton, Wong, \& Yang, 1975), where text is represented as weighted feature vectors using the Term Frequency Inverse Document Frequency (TF-IDF) scheme. TF-IDF reflects the importance of words within individual captions while down weighting common terms across the corpus, enhancing the model's ability to capture personality relevant language patterns.

Beyond sparse TF-IDF vectors, word embeddings such as Word2Vec or contextual models like BERT offer dense semantic representations that capture nuanced word relationships. These embeddings complement TF-IDF by providing richer contextual information, essential for modeling bilingual and informal language prevalent among Filipino social media users.

\section{Image Processing Theory}

Instagram's visual content necessitates effective image processing techniques to extract personality related features. Standard preprocessing steps include resizing and normalization to ensure uniformity across image inputs. Feature extraction leverages deep Convolutional Neural Networks (CNNs), specifically the VGG-19 architecture (Simonyan \& Zisserman, 2015), which has demonstrated strong performance in visual representation learning.

Extracted image features encompass both low level characteristics (e.g., color, brightness) and high level semantic content (e.g., objects, scenes) known to correlate with personality traits, as supported by prior research.

\section{Fusion Techniques}

Multimodal learning integrates heterogeneous features from text and images to improve personality prediction accuracy. Two primary fusion strategies are considered:

\begin{itemize}
	\item \textbf{Early Fusion:} Feature level integration, where extracted features from each modality are concatenated into a unified vector prior to model training.
	\item \textbf{Late Fusion:} Decision level integration, where separate models are trained per modality, and their outputs are combined for final prediction.
\end{itemize}

Following Liu et al. (2022) and Kampman et al. (2018), this research adopts an intermediate, attention based fusion mechanism that dynamically adjusts the contribution of each modality based on the target personality trait, recognizing that certain traits (e.g., Openness) may be more visually encoded, while others (e.g., Neuroticism) are better captured through language.

\section{Machine Learning Theory}

To model the relationship between extracted multimodal features and personality traits, this study employs established supervised learning algorithms:

\subsection{Logistic Regression}
\textbf{Logistic Regression (LR)} is a linear model used for binary classification. It calculates the probability of an instance belonging to a class using the sigmoid function, which maps a linear combination of features to a value between 0 and 1. The probability is given by:
$$P(y=1 | \mathbf{x}) = \frac{1}{1 + e^{-(\mathbf{w} \cdot \mathbf{x} + b)}}$$
where $P(y=1|\mathbf{x})$ is the probability of the positive class given the input feature vector $\mathbf{x}$, $\mathbf{w}$ represents the feature weights, and $b$ is the bias term.

\subsection{Support Vector Machines}
\textbf{Support Vector Machines (SVMs)} are well-suited for high-dimensional feature spaces. For classification, an SVM seeks to find the optimal hyperplane that best separates the data points of different classes by maximizing the margin between them. The optimization problem for a soft-margin SVM is formulated as:
$$\min_{\mathbf{w}, b, \xi} \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^{n} \xi_i$$
subject to the constraints $y_i(\mathbf{w} \cdot \mathbf{x}_i - b) \geq 1 - \xi_i$ and $\xi_i \geq 0$. Here, $C$ is a regularization parameter that controls the trade-off between maximizing the margin and minimizing classification errors, represented by the slack variables $\xi_i$. SVMs can capture non-linear relationships using the kernel trick, where the dot product is replaced by a kernel function, $K(\mathbf{x}_i, \mathbf{x}_j)$.

\subsection{Extreme Gradient Boosting (XGBoost)}
\textbf{Extreme Gradient Boosting (XGBoost)} is a powerful tree-based ensemble method. It builds a series of decision trees sequentially, where each new tree corrects the errors of the previous ones. The final prediction is an aggregate of the predictions from all trees. The objective function that XGBoost minimizes combines a loss function and a regularization term:
$$\text{Obj} = \sum_{i=1}^{n} l(y_i, \hat{y}_i) + \sum_{k=1}^{K} \Omega(f_k)$$
where $l(y_i, \hat{y}_i)$ is the loss function that measures the error between the true label $y_i$ and the prediction $\hat{y}_i$, and $\Omega(f_k)$ is the regularization term that penalizes the complexity of the $k$-th tree to prevent overfitting.

\section{Model Interpretability Theory}
\label{sec:interpretability_theory}
To ensure the transparency and trustworthiness of the predictive models, this study will employ a state-of-the-art model explanation framework.

\subsection{SHAP (SHapley Additive exPlanations)}
SHAP is a game-theoretic approach used to explain the output of any machine learning model. It computes the contribution of each feature to a specific prediction. The core of SHAP is the additive feature attribution model, which represents an explanation as a linear function of binary variables:
$$g(z') = \phi_0 + \sum_{j=1}^{M} \phi_j z'_j$$
In this model, $g(z')$ is the explanation model that approximates the original model's output, $z' \in \{0, 1\}^M$ indicates the presence or absence of a feature, $M$ is the number of features, $\phi_0$ is the base value (the average prediction over the dataset), and $\phi_j$ is the \textbf{SHAP value} for feature $j$. This value represents the feature's contribution to pushing the model's output away from the base value.

\section{Personality Theory}

This research operationalizes personality using the \textit{Big Five Personality Traits} model (McCrae \& Costa, 1999), encompassing Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. The Big Five framework offers a robust, empirically validated structure for personality assessment, serving as the ground truth for supervised model training.

Recent advancements in computational personality recognition, including deep learning and multimodal approaches (Mehta et al., 2019; Naz et al., 2025), provide a strong theoretical basis for leveraging Instagram content in trait prediction tasks.