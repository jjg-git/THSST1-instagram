%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   Filename    : chapter_2.tex 
%
%   Description : This file will contain your review of related works.
%                 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Related Works}
\label{sec:Related Works}


\section{Personality in Social Media Data}
\label{sec:Personality}
Research on automatic personality recognition (APR) has established robust links between digital footprints and personality traits, primarily leveraging text-based data from platforms like Twitter and Facebook. Foundational work by \citet{mairesse_using_2007} demonstrated that linguistic features (e.g., word choice, sentiment, syntactic complexity) correlate strongly with the Big Five traits, providing a framework for computational modeling. This was expanded by \citet{schwartz_personality_2013} whose open-vocabulary analysis of Facebook posts revealed nuanced patterns—such as extraverts using social activity language—highlighting social media's value as a behavioral lens. Subsequent studies confirmed cross-cultural applicability; for instance, \citet{adi_optimization_2018} and \citet{jeremy_automatic_2021} achieved high accuracy in Indonesian Twitter data using neural networks.

The advent of deep learning has refined text-based APR. \citet{majumder_deep_2017} utilized document-level neural networks to capture contextual cues, while \citet{han_knowledge_2020} developed interpretable models linking specific word categories to traits (e.g., weak correlations between neuroticism and supervision words). However, short-text platforms like Instagram pose challenges for traditional topic modeling \citep{albalawi_using_2020}. Crucially, studies in the Filipino context remain sparse. \citet{tighe_modeling_2018} pioneered this space, identifying code switching in Filipino Twitter users' language (e.g., TF–IDF unigrams most strongly predicted Conscientiousness). This work laid the groundwork for the PagkataoKo dataset \citep{tighe_acorda_2022}, a curated collection of Filipino social media data annotated with Big Five traits. While invaluable, PagkataoKo's Twitter-centric design limits insights into multimodal or platform-specific expressions on visually-oriented platforms.

Visual content offers untapped potential for personality inference. \citet{azucar_predicting_2018}'s meta-analysis synthesized evidence linking certain attributes to traits: activity statistics predict Extraversion, while demographic statistics predict Openness. Instagram-specific studies corroborate these findings; \citet{ferwerda_predicting_2018} demonstrated that HSV values and content(object recognition) modestly indicate personality although combining the two features does not result in an improvement. On the other hand \citet{branz_red_2020} found Openness correlated with warm hues (red/orange) and Conscientiousness with cooler tones (blue). These visual-semantic relationships remain underexplored in Filipino contexts, despite Instagram's dominance in Philippine social media landscapes \citep{gallardo_understanding_2024}.

Multimodal approaches significantly enhance APR accuracy by fusing complementary signals. \citet{batrinca_multimodal_2016} demonstrated that the combination of acoustic and visual non-verbal features enables statistically significant recognition of certain Big Five personality traits—such as Extraversion and Emotional Stability—particularly in goal-oriented collaborative tasks involving human-machine interactions. Similarly, \citet{lima_sequential_2022}'s LSTM-based fusion model outperformed unimodal baselines (text/audio) by 3.5\%  with LSTMs underperforming against GRU. Secuya (2021) while seemingly using multimodal data on their research, only uses TF-IDF Text Features and Twitter Account Features on their study. Furthermore, it overlooks Instagram's richer visual ecosystem where curated aesthetics \citep{harris_do_2019} yield stronger trait signals and depicted content, specifically human faces and skin \citep{machajdik_affective_2010} do yield stronger emotion signals.


\section{Text and Image Feature Extraction for Automatic Personality Recognition}

Automatic Personality Recognition (APR) from multimodal data, including text and images, has garnered significant attention in recent years due to its promising applications in understanding human behavior through online content. As the use of social media platforms like Instagram has grown, the extraction of personality-related features from users' posts has become an essential area of research. Recent studies have demonstrated that both text and image features, when combined, can enhance the performance of APR systems.

\subsection{Text Feature Extraction}

Text-based feature extraction in APR typically focuses on identifying linguistic cues that are indicative of personality traits. \citet{Mairesse2007} explored the use of various linguistic features, such as word categories, syntax, and semantic content, to predict the Big Five personality traits. Their study revealed that specific traits, such as Extraversion and Neuroticism, were strongly correlated with the use of certain types of words, such as positive or negative emotion terms. This aligns with findings from \citet{Pennebaker1999}, who identified linguistic markers such as first-person pronouns and emotional words as key indicators of personality.

With the advent of deep learning models, \citet{Christian2021} introduced a novel approach that utilizes pre-trained language models like BERT, RoBERTa, and XLNet for feature extraction, significantly improving the accuracy of text-based APR systems. These models capture the semantic meaning of words in context, which is crucial for understanding the nuances of social media posts. Furthermore, \citet{Albalawi2020} applied topic modeling techniques, specifically Latent Dirichlet Allocation (LDA), to extract latent topics from short-text data, showing that topics related to specific interests could be tied to personality traits.

\subsection{Image Feature Extraction}

Visual content, including images, offers valuable insights into users' personality traits. Instagram, as a platform primarily focused on image-sharing, presents an excellent opportunity to explore how visual features can be linked to personality. \citet{Ferwerda2018} demonstrated that image features such as color (e.g., hue, saturation, brightness) and the presence of specific content (e.g., nature scenes, selfies) can be indicative of personality traits. For instance, users who score high in Extraversion tend to post brighter and more vibrant images, while those with higher Neuroticism scores tend to post darker and more subdued images.

Moreover, \citet{Branz2020} expanded on this by showing that the use of Instagram filters also correlates with personality traits, where extroverts are more likely to use filters that enhance brightness and contrast. Additionally, \citet{Reece2017} explored how computationally extracted features from Instagram images, including color analysis and face detection, could be used to predict depression, highlighting the potential for image-based predictions in mental health and personality analysis.

\subsection{Multimodal Feature Extraction}

Combining both text and image features has been shown to improve the accuracy of personality predictions. \citet{Batrinca2016} proposed a multimodal approach for personality recognition, integrating text and visual cues from social interactions. Their findings suggest that multimodal fusion techniques can capture more comprehensive personality profiles than using either modality alone. Similarly, \citet{Skowron2016} fused linguistic features from captions and hashtags with visual features extracted from images to predict personality traits. Their study confirmed that multimodal models outperform unisource models in personality prediction tasks.

Furthermore, \citet{Lima2022b} demonstrated the effectiveness of sequential models that dynamically weigh the importance of each modality (text and image) based on context, significantly improving the recognition of personality traits across various social media datasets.

\subsection{Feature Extraction in the Context of Instagram}

Studies on Instagram, like that of \citet{Ferwerda2016}, have shown that image features such as color, saturation, and brightness are strongly tied to personality traits. However, these studies focus solely on image features and do not combine text and image modalities. This highlights the importance of distinguishing between unimodal image-based approaches and true multimodal integration, where both text and image features are used together for more robust predictions.

In contrast, \citet{Xianyu2016} applied their own multimodal learning technique (Hetero
geneity Entropy Neural Network (HENN)) to integrate both textual and visual features which outperforms the baseline systems significantly (CCA-based and Corr-AE method).

\section{Multimodal Approaches to APR}
\label{sec: MMApproaches}
Studies focusing on APR use multimodal data, meaning the input data are in different types, such as text, images, emoticons, audio, video, etc. They exhibit more accurate personality trait results than those of studies that only use one type of data, due to more features to learn. Multimodal studies use fusion techniques according to the order in the machine leraning process: early fusion and late fusion.

The earliest multimodal APR studies primarily focused on audio and visual features extracted from recorded conversations and behavioral interactions. \citet{Pianesi2008} conducted a study on multimodal behavioral analysis in multi-party meetings, utilizing SVM classifiers to predict Big Five personality traits and Locus of Control based on speech and facial expressions. Their results showed that facial features contributed significantly to extraversion classification, while vocal features were more informative for conscientiousness.

Following this, \citet{Sidorov2014} employed a similar audio-visual approach using data from the SEMAINE dataset, which consists of emotionally colored conversations. The study evaluated different segmentation techniques to improve classification accuracy, concluding that shorter segments provided better performance for certain personality traits.

Expanding on audio-visual models, \citet{Lima2022} introduced a deep learning approach, incorporating text data alongside audio and visual cues. Their research used Recurrent Neural Networks (RNNs) to process sequential multimodal data, extracting temporal dependencies in social interactions. Their model was trained on 9.1 million parameters, demonstrating the scalability and computational complexity of deep learning-based APR systems.

As social media platforms became a dominant mode of communication, researchers shifted towards analyzing text and image data to infer personality traits. \citet{Machajdik2010} introduced an affective image classification model, which extracted color, texture, and composition-based features to predict emotional responses. Although not directly designed for personality classification, their findings laid the foundation for future studies connecting visual aesthetics with personality traits.

\citet{Xianyu2016} extended this approach by introducing a heterogeneity-entropy-based deep learning framework that combined text, images, and social media interactions. Their model used Deep Belief Networks (DBNs) and Autoencoders to extract latent personality features, highlighting how unsupervised learning techniques can capture subtle personality cues across modalities.

\citet{Skowron2016} further refined multimodal approaches by integrating linguistic, visual, and metadata features from Twitter and Instagram. Their study incorporated LIWC for linguistic analysis and emotion detection techniques from Machajdik and Hanbury (2010) to extract visual features. Their findings demonstrated that cross-platform personality modeling improved accuracy, emphasizing that personality traits manifest differently across different social networks.

Advancements in machine learning-based personality prediction have allowed researchers to refine image and text-based multimodal models for social media applications. \citet{Ferwerda2018} developed a personality recognition model based on Instagram images, utilizing the Google Vision API for image content extraction and a ZeroR classifier for baseline evaluation. Their results indicated that image aesthetics and content types strongly correlate with personality traits, particularly in openness and extraversion classification.

Similarly, \citet{Batrinca2016} examined multimodal cues in team-based interactions, incorporating speech, body movements, and facial expressions to model collaborative personality traits. Their study used Hidden Markov Models (HMMs) and SVMs, demonstrating that nonverbal behavior plays a significant role in personality assessments within group settings.

\citet{Branz2020} refined the image-based personality recognition model by analyzing color preferences in Instagram photos. Their study confirmed that specific color choices (e.g., dominant red hues) correlated with openness, while blue hues were linked to conscientiousness. The study utilized k-Nearest Neighbors (k-NN) and SVMs, establishing a connection between color psychology and personality traits in digital environments.

The latest advancements in multimodal APR have shifted toward deep learning-based models, with an emphasis on personalization and adaptive AI techniques. \citet{Salam2022} introduced a personalized personality prediction model, utilizing Neural Architecture Search (NAS) to optimize Deep Neural Networks (DNNs) for different user demographics. Their study found that customized models outperformed generic APR models, reinforcing the importance of personalization in AI-driven personality recognition.

Building on deep learning methodologies, \citet{Lima2022} leveraged sequential data modeling to improve real-time personality prediction. Their model incorporated Long Short-Term Memory (LSTM) networks, demonstrating that capturing temporal dependencies enhances classification accuracy. Their research concluded that personality traits are not static but evolve based on user interactions, emphasizing the potential of adaptive AI-driven personality assessments.


\section{Filipino APR}
\label{sec: FilipinoAPR}
Filipino APR remains an underexplored domain. Existing APR research is mostly focused on English-speaking populations although there is a rise of studies that have developed specific models for different languages, namely Bahasa Indonesian, Chinese, and Egyptian \citep{Siddique2019, Salem2019, Adi2018}. What makes Filipino APR distinct from these other languages is the presence of multiple languages, some of which include an array of unique regional languages \citep{Tighe_Acorda_Agno_Gano_Go_Santiago_Sedillo_2022,tighe_modeling_2018}. Moreover, code-switching is prominent in multilingual people which adds another layer of complexity.

The first venture to Filipino APR was conducted by \citet{tighe_modeling_2018} wherein they analyzed linguistic data from 250 Filipino Twitter users. Due to there being a lack of Filipino APR datasets, \citet{Tighe_Acorda_Agno_Gano_Go_Santiago_Sedillo_2022} constructed the PagkataoKo dataset which contains data from 3,128 Filipino Twitter/Instagram users and now consists of both text and image data. Since then, several studies have been conducted using the PagkataoKo dataset but none of which so far have integrated image data.

This paper seeks to contribute to Filipino APR by exploring the effects of fusing image data as a feature. Fusion and information extraction techniques from previous multimodal studies would serve as a guide for this research’s methodology.


%Previous draft
%\citet{Pennebaker1999} explored on their study how language use can reflect the personality style of someone. Using a computerized word-based text analysis program, the structure, validity, and reliability of the written language was examined. From there it was found that one's linguistic style is a consequential way to explore personality.

%This was further explored in a study by \citet{Mairesse2007} in which the recognition of the Big Five Personality traits (Openness, Conscientiousness, Extroversion, Agreeableness, and Neuroticism) on both text and conversation was first experimented using both self rating and observer ratings of personality. From the experimentation done with the various models: classification, ranking, and regression; the ranking models performed best overall.

%The PagkataoKo dataset analyzed in this paper has been used in the studies of undergraduates, graduates, and professionals at DLSU. These various studies primarily involved modeling Filipino users’ personality traits or Automatic Personality Recognition (APR) through their usage of the Instagram and X (formerly Twitter) social media sites, as was the purpose of the creation of the dataset. 

%The dataset contains data on Filipino social media users’ social media activity on Instagram and Twitter. This includes features like post images and captions,  profile pictures, follower and following counts, and post count. It also includes the user’s BFI scores.

%Among the undergraduate and graduate studies that pursued the analysis of this dataset, the majority of them utilized only the X data, focusing on natural language processing. Techniques such as word embedding models, topic modeling, feature extraction, and other models were used to predict the BFI personality traits of users. One used both X and Instagram, but only the text data was used. There also exists another study that analyzed the visual features of Instagram image data and used this to predict personality traits. Lastly, a published study also used text processing on the X data for the same purpose.

%X was a more popular choice for analysis as the platform's main focus is that it is more text-based and the captions hold the most importance whereas on Instagram, it is more secondary. This leaves the Instagram portion of the dataset relatively unexplored compared to the X data, so there is little information about image processing in this dataset. However, this leaves open the potential for exploring images and their relation to personality, specifically the BFI scores, adding to the one research that was done on this topic. 

%Filipinos use social media in many ways. They use it for connecting with other people, sharing information, speaking out, and optimizing productivity \citep{10.1007/978-3-031-61543-6_24}. However, even though they are aware of the presence of social media, \citet{Cruz_Jamias_2013} found that Filipino researchers rarely use social media to their advantage. This demonstrates that each demographic in the Philippines has a different level of social media use.

%Social media has many effects in the Philippines. For instance, it plays a role in youth political participation. \citet{Ibardeloza2022-pz} found that social media helps the youth to be more exposed to radical involvement. It also has a positive effect on “peer interpersonal relationships” yet slightly negative on familial relationships \citep{Bristol2016TheDM}.

%Recent studies have explored the potential of Instagram image data to infer users' personality traits. \citet{ferwerda2016} analyzed features such as hue, brightness, and saturation in users' photos, finding significant correlations between these visual elements and the Big Five personality traits. Their findings suggest that individuals' choices in photo appearance can reflect underlying personality characteristics. 

%Further research by \citet{Reece2017-qw} utilized machine learning to examine Instagram photos for markers of depression. By analyzing color properties, metadata, and the presence of faces, their model successfully identified depressive indicators, highlighting the platform's potential for mental health screening. 

%Additionally, a study by \citet{Harris2019-gq} investigated the accuracy of personality portrayal on Instagram by comparing observers' perceptions of account holders' personalities with the account holders' self-reported traits. The results indicated discrepancies, suggesting that while certain visual cues can convey personality aspects, they may also lead to misinterpretations. 

%Collectively, these studies underscore the viability of leveraging Instagram image data to assess users' personality traits and mental health status, though they also caution against overreliance on visual cues due to potential misrepresentations.


%%This chapter provides a synthesis of past research, existing algorithms, and or state-of-the-art software that are related/similar to the thesis. It should not present detailed summaries of each related work, but rather present a cohesive comparison of different aspects of their work. At the end of each section and this chapter, it should be clear what research challenges and opportunities will be focused on for the proposal.

%%The sections can be about approaches, application areas, and categories of solutions that give readers an deep understanding of the current state of the field. 

%%Observe a consistent format when presenting each of the reviewed works. This must be selected in consultation with the prospective adviser.

%%\textcolor{red}{DO NOT FORGET to cite your references.} Related works can be discussed multiple times in different sections of this chapter, depending on what is being discussed or compared.


\begin{comment}
%
% IPR acknowledgement: the contents within this comment are from Ethel Ong's slides on RRL.
%
Guide on Writing your Related Works chapter
 
1. Identify the keywords with respect to your research
      One keyword = One document section
                Examples: 2.1 Story Generation Systems
			 2.2 Knowledge Representation

2.  Find references using these keywords

3.  For each of the references that you find,
        Check: Is it relevant to your research?
        Use their references to find more relevant works.

4. Identify a set of criteria for comparison.
       It will serve as a guide to help you focus on what to look for

5. Write a summary focusing on -
       What: A short description of the work
       How: A summary of the approach it utilized
       Findings: If applicable, provide the results
        Why: Relevance to your work

6. At the end of each section,  show a Table of Comparison of the related works 
   and your proposed project/system

\end{comment}
















